# GenAI Document Q&A with RAG

An enterprise-grade Retrieval-Augmented Generation (RAG) system built on Azure AI that enables intelligent question-answering over your document collections. The system combines Azure AI Foundry (GPT-4o + Embeddings) with Azure AI Search for accurate, context-aware responses.

## ğŸŒŸ Features

- **Intelligent Document Processing**: Supports PDF, DOCX, TXT, MD, and HTML formats
- **Semantic Search**: Vector embeddings with hybrid search (semantic + keyword)
- **RAG-Powered Answers**: Grounded responses with source citations
- **Interactive Web UI**: Streamlit-based interface for easy interaction
- **Enterprise-Ready**: Built on Azure with security, scalability, and observability
- **Source Attribution**: Every answer includes citations to source documents

## ğŸ—ï¸ Architecture

The solution implements a Retrieval-Augmented Generation pattern:

```
User Query â†’ Vector Search â†’ Context Retrieval â†’ LLM Generation â†’ Answer + Citations
```

**Key Components**:
- **Azure AI Foundry**: GPT-4o for generation, text-embedding-ada-002 for embeddings
- **Azure AI Search**: Hybrid search with semantic ranking
- **LangChain**: RAG orchestration and document processing
- **Streamlit**: Interactive web interface

For detailed architecture information, see [ARCHITECTURE.md](docs/ARCHITECTURE.md).

## ğŸ“‹ Prerequisites

- **Python**: 3.9 or higher
- **Azure Subscription**: With sufficient quota for Azure AI and Search services
- **Azure CLI**: Installed and configured ([Installation Guide](https://learn.microsoft.com/cli/azure/install-azure-cli))
- **PowerShell**: Required for deployment scripts (included in Windows)

## ğŸš€ Quick Start

### 1. Clone the Repository

```powershell
git clone https://github.com/dharanidharmadupu/GenAI-DocQnA-RAG.git
cd GenAI-DocQnA-RAG
```

### 2. Create Virtual Environment

```powershell
# Create virtual environment
python -m venv venv

# Activate virtual environment
.\venv\Scripts\Activate.ps1
```

### 3. Install Dependencies

```powershell
# Install required packages
pip install -r requirements.txt
```

### 4. Login to Azure

```powershell
# Login to Azure account
az login

# (Optional) Set your subscription if you have multiple
az account set --subscription "<your-subscription-id>"
```

### 5. Deploy Azure Resources

```powershell
# Deploy Azure resources (takes 5-10 minutes)
.\scripts\deploy_azure_resources.ps1
```

This script will create:
- Azure AI Foundry workspace
- Azure AI Search service
- Azure Storage account
- Required configurations and indexes

After deployment completes, the script will create a `.env` file with your service endpoints and keys.

### 6. Ingest Sample Documents

```powershell
# Ingest documents from the sample_docs folder
python src/ingestion/ingest_documents.py --docs-folder ./sample_docs

# Or ingest from a custom folder
python src/ingestion/ingest_documents.py --docs-folder "C:\path\to\your\documents"
```

The ingestion process will:
- Load documents from the specified folder
- Split text into chunks (1000 chars with 200 overlap)
- Generate embeddings using Azure AI
- Upload to Azure AI Search index

### 7. Run the Application

```powershell
# Start the Streamlit web application
streamlit run src/app.py
```

The application will open in your browser at `http://localhost:8501`.

## ğŸ“– Usage

### Using the Web Interface

1. Open the application in your browser
2. Type your question in the text input field
3. View the AI-generated answer with source citations
4. Explore retrieved document chunks in the sidebar

### Ingesting Your Own Documents

```powershell
# Ingest documents from any folder
python src/ingestion/ingest_documents.py --docs-folder "C:\your\documents"

# Supported formats: PDF, DOCX, TXT, MD, HTML
```

### Configuration

The application uses environment variables from `.env` and `config.yaml`:

**Environment Variables** (`.env`):
```env
AZURE_AI_FOUNDRY_ENDPOINT=https://your-endpoint.cognitiveservices.azure.com/
AZURE_AI_FOUNDRY_KEY=your-key
GPT_DEPLOYMENT_NAME=gpt-4o
EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002
AZURE_SEARCH_ENDPOINT=https://your-search.search.windows.net
AZURE_SEARCH_KEY=your-search-key
AZURE_SEARCH_INDEX_NAME=documents-index
```

**Configuration File** (`config.yaml`):
```yaml
document_processing:
  chunk_size: 1000
  chunk_overlap: 200
  max_retrieval_results: 5

rag:
  temperature: 0.7
  max_tokens: 1000
```

## ğŸ§ª Testing

```powershell
# Run all tests
pytest tests/

# Run specific test suite
pytest tests/test_ingestion.py
pytest tests/test_retrieval.py
pytest tests/test_rag_chain.py

# Run with coverage
pytest --cov=src tests/
```

## ğŸ“ Project Structure

```
GenAI-DocQnA-RAG/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/          # Document loading, chunking, embedding
â”‚   â”œâ”€â”€ retrieval/          # Search and retrieval logic
â”‚   â”œâ”€â”€ generation/         # LLM client and RAG chain
â”‚   â”œâ”€â”€ utils/              # Logging, metrics, helpers
â”‚   â”œâ”€â”€ app.py              # Streamlit web application
â”‚   â””â”€â”€ config.py           # Configuration management
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy_azure_resources.ps1   # Azure deployment
â”‚   â”œâ”€â”€ cleanup_resources.ps1        # Resource cleanup
â”‚   â”œâ”€â”€ setup_search_index.py        # Index configuration
â”‚   â””â”€â”€ test_connection.py           # Connection testing
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ bicep/              # Infrastructure as Code (Bicep)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md     # Architecture deep dive
â”‚   â”œâ”€â”€ DEPLOYMENT.md       # Deployment guide
â”‚   â””â”€â”€ TROUBLESHOOTING.md  # Common issues and solutions
â”œâ”€â”€ sample_docs/            # Sample documents for testing
â”œâ”€â”€ tests/                  # Unit and integration tests
â””â”€â”€ requirements.txt        # Python dependencies
```

## ğŸ”§ Troubleshooting

### Common Issues

**Issue**: `ModuleNotFoundError`
```powershell
# Ensure virtual environment is activated
.\venv\Scripts\Activate.ps1

# Reinstall dependencies
pip install -r requirements.txt
```

**Issue**: Azure deployment fails
```powershell
# Verify Azure CLI login
az account show

# Check your subscription has sufficient quota
az provider show --namespace Microsoft.CognitiveServices
```

**Issue**: Documents not appearing in search
```powershell
# Verify index exists
python scripts/test_connection.py

# Re-run ingestion with verbose logging
python src/ingestion/ingest_documents.py --docs-folder ./sample_docs --verbose
```

For more troubleshooting guidance, see [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md).

## ğŸ”’ Security & Privacy

- **Encryption**: Data encrypted at rest (AES-256) and in transit (TLS 1.3)
- **Authentication**: Azure AD integration with managed identities
- **Access Control**: RBAC for resource access
- **Key Management**: Azure Key Vault for secrets
- **Compliance**: GDPR, HIPAA, SOC 2 Type II ready

## ğŸ’° Cost Estimation

**Monthly costs** (approximate, based on usage):

| Component | Tier | Monthly Cost |
|-----------|------|--------------|
| Azure AI Foundry | Pay-as-you-go | $50-$200 |
| Azure AI Search | Basic | $75 |
| Azure Storage | Standard | $5-$10 |
| **Total** | | **$130-$285** |

Costs vary based on:
- Number of documents processed
- Query volume
- Model usage (token consumption)
- Storage size

## ğŸ“ˆ Performance

**Typical Latencies**:
- Document ingestion: ~2-5 minutes per 100 pages
- Query response time: ~2-8 seconds (end-to-end)
- P95 latency: < 5 seconds

**Scalability**:
- Documents: 1M+ (Azure Search capacity)
- Concurrent queries: 50-100 (can scale with Azure tier)
- Index size: 10GB+ (Standard tier)

## ğŸ› ï¸ Development

### Local Development

```powershell
# Activate virtual environment
.\venv\Scripts\Activate.ps1

# Run in development mode with auto-reload
streamlit run src/app.py --server.runOnSave=true

# Run tests with watch mode
pytest-watch
```

### Adding New Features

1. Create a feature branch
2. Implement changes with tests
3. Update documentation
4. Submit pull request

## ğŸ—ºï¸ Roadmap

- [ ] Multi-language support (Spanish, French, etc.)
- [ ] Advanced filtering (date range, document type)
- [ ] User authentication and authorization
- [ ] Chat history and session persistence
- [ ] Multi-tenant architecture
- [ ] Advanced analytics dashboard
- [ ] Mobile application

## ğŸ“š Additional Resources

- [Azure AI Foundry Documentation](https://learn.microsoft.com/azure/ai-studio/)
- [Azure AI Search Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview)
- [LangChain Documentation](https://python.langchain.com/)
- [RAG Best Practices](https://learn.microsoft.com/azure/architecture/ai-ml/guide/rag/rag-solution-design-and-evaluation-guide)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Author

**Dharani Dharmadupu**
- GitHub: [@dharanidharmadupu](https://github.com/dharanidharmadupu)

## ğŸ™ Acknowledgments

- Built with Azure AI services
- Powered by LangChain framework
- UI built with Streamlit

---

**Questions or issues?** Please open an issue on GitHub or refer to the [troubleshooting guide](docs/TROUBLESHOOTING.md).
